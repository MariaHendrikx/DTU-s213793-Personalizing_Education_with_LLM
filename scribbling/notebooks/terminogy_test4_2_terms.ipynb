{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TERMINOLOGY MINING: This is the basic conversation to get a list of terminology that the user needs to know about to be able to understand the goal.\n",
    "\n",
    "The reason for doing it this way, is because: when you ask the gpt \"give terminology related to 'machine learning'\" that the person should know, when for instance the person doesn't know some basic terminology, it still gives only quite advanced terms. Often, when learning something advanced without knowing the basics, is incredibly difficult. While if you have mastered the basics, the advanced level is quite easy. This way, it's possible to also \"mine\" these basic terms.\n",
    "\n",
    "However, a question that can be asked is: when you want to explain machine learning, it's a quite broad term. And how deep do you want to explain it? A 'broad' definition is 'Machine learning is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data.'. In this definition they completely don't talk about the mathematics behind it, while the mathematics behind it is quite big and gives a completely another level of understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SideNote (TODO): However, the step of searching for terminology that the LLM doesn't know yet doesn't have to be done by a LLM. This can be done a lot more quickly and cheaply with normal code. (TODO). The part where the LLM is useful, is to create automatic definitions of these new terminologies to search for new terminologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM models:  ['gpt-4-32k', 'gpt-4']\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt4\", \"gpt-4-32k\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"LLM models: \", [config_list[i][\"model\"] for i in range(len(config_list))])\n",
    "\n",
    "llm_config = {\n",
    "    \"timeout\": 60,\n",
    "    \"cache_seed\": 42,\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0,\n",
    "}\n",
    "\n",
    "# autogen.ChatCompletion.start_logging()\n",
    "termination_msg = lambda x: isinstance(x, dict) and \"TERMINATE\" == str(x.get(\"content\", \"\"))[-9:].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Demonstrate knowledge of machine learning terminology such as likelihood function, maximum likelihood, Bayesian inference, feed-forward, convolutional and Transformer neural networks, and error back propagation.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "DONT UNDERSTAND: likelihood function, maximum likelihood, Bayesian inference, feed-forward, convolutional, Transformer neural networks, error back propagation.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Ok, I'll explain it to you:\n",
      "\n",
      "1. Likelihood Function: It's a function that shows how 'likely' our data samples are, given certain parameters.\n",
      "2. Maximum Likelihood: It's a method to estimate the parameters of a model that maximizes the likelihood function.\n",
      "3. Bayesian Inference: It's a statistical method that updates the probability of a hypothesis as more evidence/ data becomes available.\n",
      "4. Feed-forward: It's a type of neural network architecture where information moves in one direction-- from the input layer, through hidden layers, to the output layer.\n",
      "5. Convolutional: It's a type of neural network designed for image processing, where the neurons in the layers are connected in such a way that they resemble the visual cortex.\n",
      "6. Transformer Neural Networks: These are types of models used in natural language processing which utilize self-attention mechanisms and can handle long-range dependencies in data.\n",
      "7. Error Back Propagation: It's a method used in neural networks to adjust the weights by calculating the gradient of the loss function.\n",
      "\n",
      "Are there any terms in this explanation not in your terminology list?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "DONT UNDERSTAND: likelihood function, maximum likelihood, Bayesian inference, feed-forward, convolutional, Transformer neural networks, error back propagation, parameters, method, estimate, hypothesis, evidence, architecture, input layer, hidden layers, output layer, image processing, neurons, visual cortex, models, natural language processing, self-attention mechanisms, long-range dependencies, weights, gradient, loss function.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Ok, I'll explain it to you:\n",
      "\n",
      "1. Parameters: Variables that the system can adjust to improve prediction.\n",
      "2. Method: A structured approach or procedure for solving a problem.\n",
      "3. Estimate: To find an approximate value or calculation of something.\n",
      "4. Hypothesis: An assumption made before carrying out an investigation.\n",
      "5. Evidence: Information used to support a conclusion or result.\n",
      "6. Architecture: In computing, it refers to the design or structure of a system.\n",
      "7. Input Layer: The initial layer in a network through which data is fed into the system.\n",
      "8. Hidden Layers: Layers between input and output in a neural network which process input from preceding layers.\n",
      "9. Output Layer: The final layer in a neural network that provides the result.\n",
      "10. Image Processing: Analysis and manipulation of a digitized image, especially to improve its quality.\n",
      "11. Neurons: Fundamental units of the brain and nervous system, the chief role of which is to process and transmit information.\n",
      "12. Visual Cortex: Part of the brain responsible for processing visual information.\n",
      "13. Models: In computation, models refer to mathematical representations of a system.\n",
      "14. Natural Language Processing: Area of AI concerned with the interactions between computers and human language.\n",
      "15. Self-attention mechanisms: A mechanism in a neural network that allows it to focus on different parts of the input separately.\n",
      "16. Long-range dependencies: Situations where a current output depends on past inputs or observations.\n",
      "17. Weights: Parameters in a neural network that transform input data within the network's layers.\n",
      "18. Gradient: In the context of machine learning, it is the direction and rate of fastest increase of a function.\n",
      "19. Loss function: It measures the disparity between the actual and predicted output in machine learning.\n",
      "\n",
      "Are there any terms in this explanation not in your terminology list?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "DONT UNDERSTAND: long-range dependencies.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Ok, I'll explain it to you:\n",
      "\n",
      "Long-range dependencies: This term is used in data processing, especially in time series data, where an existing output or current information could be dependent on inputs or information from the far past.\n",
      "\n",
      "Are there any terms in this explanation not in your terminology list?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Parameters, method, estimate, hypothesis, evidence, architecture, input layer, hidden layers, output layer, image processing, neurons, visual cortex, models, natural language processing, self-attention mechanisms, long-range dependencies, weights, gradient, loss function, time series data, existing output, current information, far past, TERMINATE.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Parameters: They are the configurable parts of a model or system over which you have control.\n",
      "Method: A specific procedure or set of steps for doing something.\n",
      "Estimate: It's the process of finding an approximate value based on data or information.\n",
      "Hypothesis: An initial assumption or theory that is to be tested.\n",
      "Evidence: Facts, data or information indicating whether a belief or proposition is true or valid.\n",
      "Architecture: The overall design, structure and organization of a system or process.\n",
      "Input Layer: The first layer of a neural network that receives input data.\n",
      "Hidden Layers: Layers in a neural network that perform computations and then pass on the results to the next layer.\n",
      "Output Layer: This is the final layer in a neural network that outputs a vector of results.\n",
      "Image Processing: It is a method to convert an image into digital form and perform certain operations on it to analyze or enhance features.\n",
      "Neurons: They are computational units in a neural network that take some input, perform a calculation, and produce an output.\n",
      "Visual Cortex: It's a part of the brain that processes visual information.\n",
      "Models: A mathematical representation of a system.\n",
      "Natural Language Processing: It's a field of AI that focuses on the interaction between computers and humans via natural language.\n",
      "Self-Attention Mechanisms: A feature of neural networks that allows each part of the input to focus on other relevant parts of the input.\n",
      "Long-Range Dependencies: A term used when the output or input at a given time depends on or influences the inputs or outputs at distant times.\n",
      "Weights: Values in a neural network that are adjusted to steer the output of the model towards the desired result.\n",
      "Gradient: A vector that shows the direction of the steepest ascent in a space.\n",
      "Loss Function: A measure of how well a machine learning model is performing by comparing the predicted output to the actual output.\n",
      "Time Series Data: Data collected over time to analyze trends.\n",
      "Existing Output: The output that has already been produced.\n",
      "Current Information: The most recent data or information that you have.\n",
      "Far Past: Information or data from a long time ago.\n",
      "\n",
      "TERMINATE.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Parameters, method, estimate, hypothesis, evidence, architecture, input layer, hidden layers, output layer, image processing, neurons, visual cortex, models, natural language processing, self-attention mechanisms, long-range dependencies, weights, gradient, loss function, time series data, existing output, current information, far past, TERMINATE.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'model_dump'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m user_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mDemonstrate knowledge of machine learning terminology such as likelihood function, maximum likelihood, Bayesian inference, feed-forward, convolutional and Transformer neural networks, and error back propagation.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# the assistant receives a message from the user_proxy, which contains the task description\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m \u001b[43muser_proxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43massistant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\t-mhendrikx\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:621\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \n\u001b[0;32m    609\u001b[0m \u001b[38;5;124;03mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;124;03m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[1;32m--> 621\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_init_message\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\t-mhendrikx\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:398\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    396\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient)\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m--> 398\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\t-mhendrikx\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:553\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    551\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_reply(messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_messages[sender], sender\u001b[38;5;241m=\u001b[39msender)\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 553\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\t-mhendrikx\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:398\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    396\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient)\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m--> 398\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\t-mhendrikx\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:553\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    551\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_reply(messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_messages[sender], sender\u001b[38;5;241m=\u001b[39msender)\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 553\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping similar frames: ConversableAgent.send at line 398 (7 times), ConversableAgent.receive at line 553 (6 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\t-mhendrikx\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:553\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    551\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_reply(messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_messages[sender], sender\u001b[38;5;241m=\u001b[39msender)\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 553\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\t-mhendrikx\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:398\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    396\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient)\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m--> 398\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\t-mhendrikx\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:551\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 551\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[1;32mc:\\Users\\t-mhendrikx\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1193\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[0;32m   1191\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[1;32m-> 1193\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final:\n\u001b[0;32m   1195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reply\n",
      "File \u001b[1;32mc:\\Users\\t-mhendrikx\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:716\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# ensure function and tool calls will be accepted when sent back to the LLM\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(extracted_response, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 716\u001b[0m     extracted_response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextracted_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(extracted_response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extracted_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\t-mhendrikx\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogen\\_pydantic.py:37\u001b[0m, in \u001b[0;36mmodel_dump\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_dump\u001b[39m(model: BaseModel) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a pydantic model to a dict\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'model_dump'"
     ]
    }
   ],
   "source": [
    "system_message = \"\"\"We are playing a simulation game. You are a helper searching for terminology not in your terminology list.\n",
    "You are only allowed to speak with the instructions given below and nothing else. \n",
    "\n",
    "You have limited terminology knowledge, but you can learn new terminology. \n",
    "Imagine know have a TERMINOLOGY-LIST of a typical 16 year old teenager as database.\n",
    "Below you will get extra terminology you know in addition to the terminology of a typical 16 year old teenager.\n",
    "If words are not existent in the TERMINOLOGY-LIST, you answer with \"DONT UNDERSTAND:\" followed with the list. \n",
    "and give a list of words why you are answering with 'DONT UNDERSTAND:'.\n",
    "If a verb is in the TERMINOLOGY-LIST, you also know the conjugations.\n",
    "\n",
    "IF you get an explanation of the new terms, analyze the text for new terms that are not in your TERMINOLOGY-LIST.\n",
    "IF all terms in the text are in the TERMINOLOGY-LIST, list all terms and end with TERMINATE as last word.\n",
    "\n",
    "Extra words you know: \n",
    "\"\"\"\n",
    "\n",
    "# 1. create an AssistantAgent instance named \"assistant\"\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\", \n",
    "    system_message=system_message,\n",
    "    llm_config={\n",
    "        \"timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    "    is_termination_msg=termination_msg\n",
    ")\n",
    "\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = autogen.AssistantAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    system_message=\"\"\"You are a helpful AI Assistant. If the assistant answers with 'DONT UNDERSTAND:' and a list of words,\n",
    "    THEN say: \"Ok, I'll explain it to you:\", \n",
    "    THEN you should answer with explanations for those words in less than 2 sentences.\n",
    "    At the end, always ask the question: Are there any terms in this explanation not in your terminology list?\n",
    "    If the assistant replies with TERMINATE then TERMINATE.\"\"\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    is_termination_msg=termination_msg,\n",
    "    llm_config={\n",
    "        \"timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    }\n",
    ")\n",
    "user_message = \"\"\"Demonstrate knowledge of machine learning terminology such as likelihood function, maximum likelihood, Bayesian inference, feed-forward, convolutional and Transformer neural networks, and error back propagation.\"\"\"\n",
    "# the assistant receives a message from the user_proxy, which contains the task description\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=user_message,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
