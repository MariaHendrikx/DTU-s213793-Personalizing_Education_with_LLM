{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEVEL: determining the level of the user by looking at the terminology it knows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM models:  ['gpt-4-32k', 'gpt-4']\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt4\", \"gpt-4-32k\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"LLM models: \", [config_list[i][\"model\"] for i in range(len(config_list))])\n",
    "\n",
    "llm_config = {\n",
    "    \"timeout\": 60,\n",
    "    \"cache_seed\": 42,\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0,\n",
    "}\n",
    "\n",
    "# autogen.ChatCompletion.start_logging()\n",
    "termination_msg = lambda x: isinstance(x, dict) and \"TERMINATE\" == str(x.get(\"content\", \"\"))[-9:].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "TOPIC: machine learning\n",
      "TERMINOLOGY: {\n",
      "    \"terminology\": [\n",
      "        \"down\", \"under\", \"over\", \"between\",\n",
      "        \"neural network\", \"deep learning\", \"machine learning\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "The simulated user seems to have a beginner's knowledge level on the topic of machine learning. The terminologies mentioned only include basic concepts and do not include any advanced terms related to this subject matter.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "system_message = \"\"\"We are playing a simulation game. \n",
    "You are assessing the level of a simulated user\n",
    "that only knows the terminology given and nothing more. You need to assess the level of the simulated user on the topic given.\n",
    "The topic will be given after TOPIC.\n",
    "The known terminology will be given after TERMINOLOGY.\n",
    "\"\"\"\n",
    "\n",
    "# 1. create an AssistantAgent instance named \"assistant\"\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\", \n",
    "    system_message=system_message,\n",
    "    llm_config={\n",
    "        \"timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    "    is_termination_msg=termination_msg\n",
    ")\n",
    "\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = autogen.AssistantAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    system_message=\"\"\"You always answer with TOPIC: topic; TERMINOLOGY: list of terminology.\"\"\",\n",
    "    max_consecutive_auto_reply=0,\n",
    "    is_termination_msg=termination_msg,\n",
    "    llm_config={\n",
    "        \"timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    }\n",
    ")\n",
    "user_message = \"\"\"TOPIC: machine learning\n",
    "TERMINOLOGY: {\n",
    "    \"terminology\": [\n",
    "        \"down\", \"under\", \"over\", \"between\",\n",
    "        \"neural network\", \"deep learning\", \"machine learning\"\n",
    "    ]\n",
    "}\"\"\"\n",
    "# the assistant receives a message from the user_proxy, which contains the task description\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=user_message,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
