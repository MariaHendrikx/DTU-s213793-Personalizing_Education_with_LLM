{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'autogen' has no attribute 'config_list_from_json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mautogen\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m config_list \u001b[38;5;241m=\u001b[39m \u001b[43mautogen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_list_from_json\u001b[49m(\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOAI_CONFIG_LIST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     file_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     filter_dict\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-35-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-35-turbo-0613\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4-32k\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      8\u001b[0m     },\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM models: \u001b[39m\u001b[38;5;124m\"\u001b[39m, [config_list[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(config_list))])\n\u001b[0;32m     13\u001b[0m PROBLEM \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan you tell me what level of english I probably have with this knowledge of terminology?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'autogen' has no attribute 'config_list_from_json'"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-3.5-turbo\", \"gpt-35-turbo\", \"gpt-35-turbo-0613\", \"gpt-4\", \"gpt4\", \"gpt-4-32k\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"LLM models: \", [config_list[i][\"model\"] for i in range(len(config_list))])\n",
    "\n",
    "PROBLEM = \"Can you tell me what level of english I probably have with this knowledge of terminology?\"\n",
    "\n",
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "import chromadb\n",
    "\n",
    "llm_config = {\n",
    "    \"timeout\": 60,\n",
    "    \"cache_seed\": 42,\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0,\n",
    "}\n",
    "\n",
    "# autogen.ChatCompletion.start_logging()\n",
    "termination_msg = lambda x: isinstance(x, dict) and \"TERMINATE\" == str(x.get(\"content\", \"\"))[-9:].upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_terminology_expert(message):\n",
    "    # 1. create an RetrieveAssistantAgent instance named \"assistant\"\n",
    "    terminology_assistant = RetrieveAssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        system_message=\"You are a helpful assistant.\",\n",
    "        llm_config={\n",
    "            \"timeout\": 600,\n",
    "            \"cache_seed\": 42,\n",
    "            \"config_list\": config_list,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # 2. create an UserProxyAgent instance named \"user\"\n",
    "    # This agents uses RAG to retrieve information from the document.\n",
    "    terminology_expert = RetrieveUserProxyAgent(\n",
    "        name=\"terminology_expert\",\n",
    "        is_termination_msg=termination_msg,\n",
    "        system_message=\"\"\"Assistant who has knowledge of all the terminology that the user knows. \n",
    "        Analyzes the terminology and determines the level of the user.\n",
    "        End the conversation with a summary of the user's level regarding the question/problem given.\n",
    "        \"\"\",\n",
    "        human_input_mode=\"NEVER\",\n",
    "        max_consecutive_auto_reply=2,\n",
    "        retrieve_config={\n",
    "            \"task\": \"code\",\n",
    "            \"docs_path\": \"../data/memory_longterm.json\",\n",
    "            \"chunk_token_size\": 1000,\n",
    "            \"model\": config_list[0][\"model\"],\n",
    "            \"client\": chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n",
    "            \"collection_name\": \"user1_terminology\",\n",
    "            \"get_or_create\": True,\n",
    "        },\n",
    "        code_execution_config=False,  # we don't want to execute code in this case.\n",
    "    )\n",
    "\n",
    "    # 3. initiate chat between \"user\" and \"assistant\"\n",
    "    terminology_assistant.reset()# reset the assistant. Always reset the assistant before starting a new conversation.\n",
    "    terminology_expert.initiate_chat(terminology_assistant, problem=PROBLEM)\n",
    "    return terminology_expert.last_message()[\"content\"]\n",
    "    ## -------------------------------------------------------------------------------------------------- ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_background_expert(message):\n",
    "    # 1. create an RetrieveAssistantAgent instance named \"assistant\"\n",
    "    background_assistant = RetrieveAssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        system_message=\"\"\"Assistant who has knowledge of all the background of the user. \n",
    "        Analyzes the documents and tries to formulate an answer to the given question.\n",
    "        End the conversation with a summary of the user's level regarding the question/problem given.\n",
    "        \"\"\",\n",
    "        llm_config={\n",
    "            \"timeout\": 600,\n",
    "            \"cache_seed\": 42,\n",
    "            \"config_list\": config_list,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # 2. create an UserProxyAgent instance named \"user\"\n",
    "    # This agents uses RAG to retrieve information from the document.\n",
    "    background_expert = RetrieveUserProxyAgent(\n",
    "        name=\"background_expert\",\n",
    "        is_termination_msg=termination_msg,\n",
    "        system_message=\"Assistant who has knowledge of the background of a user.\",\n",
    "        human_input_mode=\"NEVER\",\n",
    "        max_consecutive_auto_reply=2,\n",
    "        retrieve_config={\n",
    "            \"task\": \"code\",\n",
    "            \"docs_path\": \"../data/background/CV_2023_DataAndAI.pdf\",\n",
    "            \"chunk_token_size\": 1000,\n",
    "            \"model\": config_list[0][\"model\"],\n",
    "            \"client\": chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n",
    "            \"collection_name\": \"user1_background\",\n",
    "            \"get_or_create\": True,\n",
    "        },\n",
    "        code_execution_config=False,  # we don't want to execute code in this case.\n",
    "    )\n",
    "\n",
    "    # 3. initiate chat between \"user\" and \"assistant\"\n",
    "    background_assistant.reset()# reset the assistant. Always reset the assistant before starting a new conversation.\n",
    "    background_expert.initiate_chat(background_assistant, problem=PROBLEM)\n",
    "    return background_expert.last_message()[\"content\"]\n",
    "    ## -------------------------------------------------------------------------------------------------- ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_for_student = autogen.AssistantAgent(\n",
    "    name=\"assistant_for_student\",\n",
    "    system_message=\"\"\"You are a helpful assistant. \n",
    "    First ask the terminology_expert about what terminology the user knows.\n",
    "    THEN ask the background_expert about the background of the user.'\n",
    "    THEN conclude what the current level of the user is.\n",
    "    THEN reply TERMINATE\"\"\",\n",
    "    llm_config={\n",
    "        \"timeout\": 600,\n",
    "        \"cache_seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "        \"temperature\": 0,\n",
    "        \"functions\": [\n",
    "            {\n",
    "                \"name\": \"ask_terminology_expert\",\n",
    "                \"description\": \"ask terminology_expert when you need to know the terminology that the user knows.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"message\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"\"\"question to ask terminology_expert. Ensure the question includes enough context.\n",
    "                            The expert does not know the conversation between you and the user unless you share the conversation\n",
    "                            with the expert.\"\"\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"message\"],\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"ask_background_expert\",\n",
    "                \"description\": \"ask background_expert when you need to know the background of a user.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"message\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"\"\"question to ask background_expert. Ensure the question includes enough context. \n",
    "                            The expert does not know the conversation between you and the user unless you share the conversation with the expert.\"\"\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"message\"],\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "student = autogen.UserProxyAgent(\n",
    "    name=\"student\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    code_execution_config={\"work_dir\": \"student\"},\n",
    "    function_map={\"ask_terminology_expert\": ask_terminology_expert, \n",
    "                  \"ask_background_expert\": ask_background_expert},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mstudent\u001b[0m (to assistant_for_student):\n",
      "\n",
      "Can you tell me about the level of the user's english?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant_for_student\u001b[0m (to student):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: ask_terminology_expert *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"message\": \"Can you provide information about the English terminology that the user knows?\"\n",
      "}\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION ask_terminology_expert...\u001b[0m\n",
      "Trying to create collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-mhendrikx\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Directory ../data/memory_longterm.json does not exist.\n",
      "Directory ../data/memory_longterm.json does not exist.\n",
      "Number of requested results 20 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_ids:  [['doc_0']]\n",
      "\u001b[32mAdding doc_id doc_0 to context.\u001b[0m\n",
      "\u001b[33mterminology_expert\u001b[0m (to assistant):\n",
      "\n",
      "You're a retrieve augmented coding assistant. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user.\n",
      "If you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\n",
      "For code generation, you must obey the following rules:\n",
      "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
      "Rule 2. You must follow the formats below to write your code:\n",
      "```language\n",
      "# your code\n",
      "```\n",
      "\n",
      "User's question is: Can you tell me what level of english I probably have with this knowledge of terminology?\n",
      "\n",
      "Context is: {\n",
      "    \"terminology I know\": [\n",
      "        \"hello\", \"goodbye\", \"please\", \"thank you\",\n",
      "        \"yes\", \"no\", \"name\", \"age\",\n",
      "        \"family\", \"friend\", \"house\", \"school\",\n",
      "        \"book\", \"pen\", \"chair\", \"table\",\n",
      "        \"dog\", \"cat\", \"apple\", \"bread\",\n",
      "        \"water\", \"tea\", \"coffee\", \"milk\",\n",
      "        \"happy\", \"sad\", \"big\", \"small\",\n",
      "        \"hot\", \"cold\", \"good\", \"bad\",\n",
      "        \"eat\", \"drink\", \"read\", \"write\",\n",
      "        \"speak\", \"listen\", \"walk\", \"run\",\n",
      "        \"have\", \"do\", \"make\", \"go\",\n",
      "        \"I\", \"you\", \"he\", \"she\",\n",
      "        \"we\", \"they\", \"my\", \"your\",\n",
      "        \"his\", \"her\", \"our\", \"their\",\n",
      "        \"this\", \"that\", \"here\", \"there\",\n",
      "        \"today\", \"tomorrow\", \"yesterday\",\n",
      "        \"morning\", \"afternoon\", \"evening\",\n",
      "        \"day\", \"night\", \"week\", \"month\",\n",
      "        \"year\", \"time\", \"early\", \"late\",\n",
      "        \"always\", \"usually\", \"sometimes\", \"never\",\n",
      "        \"in\", \"on\", \"at\", \"with\",\n",
      "        \"for\", \"from\", \"to\", \"up\",\n",
      "        \"down\", \"under\", \"over\", \"between\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to terminology_expert):\n",
      "\n",
      "Given the list of terms you know, it seems like you may have an elementary (A1-A2 CEFR scale) level of English. These terms cover some basics of vocabulary including personal pronouns, simple verbs, adjectives, and prepositions, as well as common phrases and objects. However, the proficiency of a language is not just about knowing words but also involves understanding grammar, being able to form sentences, and comprehension. So without that information, it's difficult to give a precise assessment.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mterminology_expert\u001b[0m (to assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to terminology_expert):\n",
      "\n",
      "UPDATE CONTEXT\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32mUpdating context and resetting conversation.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 60 is greater than number of elements in index 1, updating n_results = 1\n",
      "Number of requested results 100 is greater than number of elements in index 1, updating n_results = 1\n",
      "Number of requested results 140 is greater than number of elements in index 1, updating n_results = 1\n",
      "Number of requested results 180 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_ids:  [['doc_0']]\n",
      "doc_ids:  [['doc_0']]\n",
      "doc_ids:  [['doc_0']]\n",
      "doc_ids:  [['doc_0']]\n",
      "\u001b[32mNo more context, will terminate.\u001b[0m\n",
      "\u001b[33mterminology_expert\u001b[0m (to assistant):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mstudent\u001b[0m (to assistant_for_student):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"ask_terminology_expert\" *****\u001b[0m\n",
      "TERMINATE\n",
      "\u001b[32m*******************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "assistant_for_student.reset()\n",
    "# the assistant receives a message from the student, which contains the task description\n",
    "student.initiate_chat(\n",
    "    assistant_for_student,\n",
    "    message=\"\"\"Can you tell me about the level of the user's english?\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "import chromadb\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"/tmp/chromadb\")\n",
    "collection = client.get_collection(name=\"groupchat\")\n",
    "client.delete_collection(name=\"groupchat\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
