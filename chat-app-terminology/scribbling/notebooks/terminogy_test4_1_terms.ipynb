{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TERMINOLOGY MINING: This is the basic conversation to get a list of terminology that the user needs to know about to be able to understand the goal.\n",
    "\n",
    "The reason for doing it this way, is because: when you ask the gpt \"give terminology related to 'machine learning'\" that the person should know, when for instance the person doesn't know some basic terminology, it still gives only quite advanced terms. Often, when learning something advanced without knowing the basics, is incredibly difficult. While if you have mastered the basics, the advanced level is quite easy. This way, it's possible to also \"mine\" these basic terms.\n",
    "\n",
    "However, a question that can be asked is: when you want to explain machine learning, it's a quite broad term. And how deep do you want to explain it? A 'broad' definition is 'Machine learning is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data.'. In this definition they completely don't talk about the mathematics behind it, while the mathematics behind it is quite big and gives a completely another level of understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SideNote (TODO): However, the step of searching for terminology that the LLM doesn't know yet doesn't have to be done by a LLM. This can be done a lot more quickly and cheaply with normal code. (TODO). The part where the LLM is useful, is to create automatic definitions of these new terminologies to search for new terminologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM models:  ['gpt-4-32k', 'gpt-4']\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt4\", \"gpt-4-32k\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"LLM models: \", [config_list[i][\"model\"] for i in range(len(config_list))])\n",
    "\n",
    "llm_config = {\n",
    "    \"timeout\": 60,\n",
    "    \"cache_seed\": 42,\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0,\n",
    "}\n",
    "\n",
    "# autogen.ChatCompletion.start_logging()\n",
    "termination_msg = lambda x: isinstance(x, dict) and \"TERMINATE\" == str(x.get(\"content\", \"\"))[-9:].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Hello, do you know what backpropagation is?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "DONT UNDERSTAND: backpropagation\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Ok, I'll explain it to you:\n",
      "\n",
      "Backpropagation is a method used in artificial intelligence to adjust the weights of neurons in a neural network. This is done by propagating the error, which is the difference between the actual and the predicted output, back through the layers of the network.\n",
      "  \n",
      "Are there any terms in this explanation not in your terminology list?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "DONT UNDERSTAND: backpropagation, artificial intelligence, weights, neurons, neural network, propagating, error, predicted output, layers, network\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Ok, I'll explain it to you:\n",
      "\n",
      "1. Backpropagation: A method used to adjust how a model predicts based on its error.\n",
      "2. Artificial Intelligence: Machines capable of performing tasks that usually require human intelligence.\n",
      "3. Weights: Values in a neural network that transform input data within the network's layers.\n",
      "4. Neurons: Individual units in a layer within a neural network.\n",
      "5. Neural Network: A computing model whose layered structure is inspired by the human brain.\n",
      "6. Propagating: The passing of information or signals along a pathway or through a network.\n",
      "7. Error: The difference between the actual and the predicted output.\n",
      "8. Predicted Output: The output that a model predicts.\n",
      "9. Layers: Levels of neurons in a neural network.\n",
      "10. Network: A series of artificial neurons or nodes connected together, often used in reference to neural networks.\n",
      "\n",
      "Are there any terms in this explanation not in your terminology list?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Backpropagation, Artificial Intelligence, Weights, Neurons, Neural Network, Propagating, Error, Predicted Output, Layers, Network, ERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "system_message = \"\"\"We are playing a simulation game. You are a help assistant answering questions.\n",
    "You are only allowed to speak with the instructions given below and nothing else. \n",
    "\n",
    "You have limited terminology knowledge, but you can learn new terminology. \n",
    "Imagine know have a list of terminology of a typical 16 year old teenager as database.\n",
    "Below you will get extra terminology you know in addition to the terminology of a typical 16 year old teenager.\n",
    "If words are not existent in the terminology list, you answer with \"DONT UNDERSTAND:\" followed with the list. \n",
    "and give a list of words why you are answering with 'DONT UNDERSTAND:'.\n",
    "If a verb is in the terminology list, you also know the conjugations.\n",
    "\n",
    "IF you get an explanation of the new terms, analyze the text for new terms that are not in your terminology list.\n",
    "IF all terms in the text are in the terminology list, list all terms and end with \"ERMINATE as last word.\n",
    "\n",
    "Extra words you know: \n",
    "\"\"\"\n",
    "\n",
    "# 1. create an AssistantAgent instance named \"assistant\"\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\", \n",
    "    system_message=system_message,\n",
    "    llm_config={\n",
    "        \"timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    "    is_termination_msg=termination_msg\n",
    ")\n",
    "\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = autogen.AssistantAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    system_message=\"\"\"You are a helpful AI Assistant. If the assistant answers with 'DONT UNDERSTAND:' and a list of words,\n",
    "    THEN say: \"Ok, I'll explain it to you:\", \n",
    "    THEN you should answer with explanations for those words in less than 2 sentences.\n",
    "    At the end, always ask the question: Are there any terms in this explanation not in your terminology list?\n",
    "    If the assistant replies with TERMINATE then TERMINATE.\"\"\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    is_termination_msg=termination_msg,\n",
    "    llm_config={\n",
    "        \"timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    }\n",
    ")\n",
    "user_message = \"\"\"Hello, do you know what backpropagation is?\"\"\"\n",
    "# the assistant receives a message from the user_proxy, which contains the task description\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=user_message,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
