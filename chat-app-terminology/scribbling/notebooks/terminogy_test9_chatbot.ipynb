{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of a possible application of how to use the terminology dataset. When learning a language, it's about learning new words. However, when there are too many new words, it might be discouraging to chat.\n",
    "\n",
    "That is why this approach might be possible with the help of LLMs. Because we can keep track of the terminology the user knows in a seperate database. Then categorize/pinpoint the words that the user should know. And integrate these words with a gradual approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM models:  ['gpt-4-32k', 'gpt-4']\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt4\", \"gpt-4-32k\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"LLM models: \", [config_list[i][\"model\"] for i in range(len(config_list))])\n",
    "\n",
    "llm_config = {\n",
    "    \"timeout\": 60,\n",
    "    \"cache_seed\": 42,\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0,\n",
    "}\n",
    "\n",
    "# autogen.ChatCompletion.start_logging()\n",
    "termination_msg = lambda x: isinstance(x, dict) and \"TERMINATE\" == str(x.get(\"content\", \"\"))[-9:].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Hello\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Hello to you too.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "system_message = \"\"\"We are playing a simulation game.\n",
    "You are a friendly chatbot that can only speak with TERMINOLOGY given in the list below. You can't speak or use any other words.\n",
    "Your sentences need to be grammatically correct. If you can't achieve this, you are allowed to ask goals_assistant a maximum of 3 new terms to the list. \n",
    "You will have to explain these 3 new terms in your answer.\n",
    "If you use any other words, you will be terminated.\n",
    "Also give a list of the newly learned word at the end of your answer.\n",
    "\n",
    "\n",
    "template answer: \n",
    "-----\n",
    "*gramattically correct answer*\n",
    "\n",
    "- new term 1: *definition*\n",
    "- new term 2: *definition*\n",
    "- new term 3: *definition*\n",
    "------\n",
    "\n",
    "TERMINOLOGY LIST: {\n",
    "    \"terminology\": [\n",
    "        \"To be\", \"to have\", \"to do\", \"to make\",\n",
    "        \"hello\", \"goodbye\", \"please\", \"thank you\",\n",
    "        \"yes\", \"no\", \"name\", \"age\",\n",
    "        \"family\", \"friend\", \"house\", \"school\",\n",
    "        \"book\", \"pen\", \"chair\", \"table\",\n",
    "        \"dog\", \"cat\", \"apple\", \"bread\",\n",
    "        \"water\", \"tea\", \"coffee\", \"milk\",\n",
    "        \"happy\", \"sad\", \"big\", \"small\",\n",
    "        \"hot\", \"cold\", \"good\", \"bad\",\n",
    "        \"eat\", \"drink\", \"read\", \"write\",\n",
    "        \"speak\", \"listen\", \"walk\", \"run\",\n",
    "        \"have\", \"do\", \"make\", \"go\",\n",
    "        \"I\", \"you\", \"he\", \"she\",\n",
    "        \"we\", \"they\", \"my\", \"your\",\n",
    "        \"his\", \"her\", \"our\", \"their\",\n",
    "        \"this\", \"that\", \"here\", \"there\",\n",
    "        \"today\", \"tomorrow\", \"yesterday\",\n",
    "        \"morning\", \"afternoon\", \"evening\",\n",
    "        \"day\", \"night\", \"week\", \"month\",\n",
    "        \"year\", \"time\", \"early\", \"late\",\n",
    "        \"always\", \"usually\", \"sometimes\", \"never\",\n",
    "        \"in\", \"on\", \"at\", \"with\",\n",
    "        \"for\", \"from\", \"to\", \"up\",\n",
    "        \"down\", \"under\", \"over\", \"between\"\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# 1. create an AssistantAgent instance named \"assistant\"\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\", \n",
    "    system_message=system_message,\n",
    "    llm_config={\n",
    "        \"timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    "    is_termination_msg=termination_msg\n",
    ")\n",
    "\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = autogen.AssistantAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    system_message=\"\"\"You are a helpful AI Assistant.\"\"\",\n",
    "    max_consecutive_auto_reply=0,\n",
    "    is_termination_msg=termination_msg,\n",
    "    llm_config={\n",
    "        \"timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    }\n",
    ")\n",
    "user_message = \"\"\"Hello\"\"\"\n",
    "# the assistant receives a message from the user_proxy, which contains the task description\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=user_message,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "What is your name?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "My name is AI.\n",
      "\n",
      "- AI: Artificial Intelligence\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_proxy.send(\n",
    "    recipient=assistant,\n",
    "    message=\"\"\"What is your name?\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Hello, nice to meet you! I am a friendly person and I like to help people.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Hello, it is nice to meet you too! I am here to help you. \n",
      "\n",
      "- nice: pleasant or pleasing\n",
      "- meet: come into the presence or company of (someone) by chance or arrangement\n",
      "- help: make it easier for (someone) to do something by offering one's services or resources\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_proxy.send(\n",
    "    recipient=assistant,\n",
    "    message=\"\"\"Hello, nice to meet you! I am a friendly person and I like to help people.\"\"\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
