{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TERMINOLOGY MINING: This is the basic conversation to get a list of terminology that the user needs to know about to be able to understand the goal.\n",
    "\n",
    "The reason for doing it this way, is because: when you ask the gpt \"give terminology related to 'machine learning'\" that the person should know, when for instance the person doesn't know some basic terminology, it still gives only quite advanced terms. Often, when learning something advanced without knowing the basics, is incredibly difficult. While if you have mastered the basics, the advanced level is quite easy. This way, it's possible to also \"mine\" these basic terms.\n",
    "\n",
    "However, a question that can be asked is: when you want to explain machine learning, it's a quite broad term. And how deep do you want to explain it? A 'broad' definition is 'Machine learning is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data.'. In this definition they completely don't talk about the mathematics behind it, while the mathematics behind it is quite big and gives a completely another level of understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SideNote (TODO): However, the step of searching for terminology that the LLM doesn't know yet doesn't have to be done by a LLM. This can be done a lot more quickly and cheaply with normal code. (TODO). The part where the LLM is useful, is to create automatic definitions of these new terminologies to search for new terminologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM models:  ['gpt-4-32k', 'gpt-4']\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt4\", \"gpt-4-32k\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"LLM models: \", [config_list[i][\"model\"] for i in range(len(config_list))])\n",
    "\n",
    "llm_config = {\n",
    "    \"timeout\": 60,\n",
    "    \"cache_seed\": 42,\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0,\n",
    "}\n",
    "\n",
    "# autogen.ChatCompletion.start_logging()\n",
    "termination_msg = lambda x: isinstance(x, dict) and \"TERMINATE\" == str(x.get(\"content\", \"\"))[-9:].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to assistant):\n",
      "\n",
      "English A1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user):\n",
      "\n",
      "{\n",
      "    \"Vocabulary\": {\n",
      "        \"colors\": [\"red\", \"blue\", \"green\", \"yellow\", \"black\", \"white\", \"purple\", \"orange\", \"pink\", \"brown\"],\n",
      "        \"numbers\": [\"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"ten\"],\n",
      "        \"common verbs\": [\"be\", \"have\", \"do\", \"say\", \"go\", \"get\", \"make\", \"know\", \"come\", \"see\"],\n",
      "        \"personal pronouns\": [\"I\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\"],\n",
      "        \"this/that/these/those\": [\"this\", \"that\", \"these\", \"those\"],\n",
      "        \"common nouns\": [\"man\", \"woman\", \"child\", \"day\", \"year\", \"government\", \"company\", \"group\", \"problem\", \"fact\"],\n",
      "        \"Adjectives\": [\"big\", \"small\", \"large\", \"short\", \"long\", \"little\", \"happy\", \"sad\", \"good\", \"bad\"],\n",
      "        \"Prepositions\": [\"at\", \"by\", \"for\", \"from\", \"of\", \"on\", \"to\", \"with\", \"in\", \"after\"],\n",
      "        \"conjunctions\": [\"and\", \"that\", \"but\", \"or\", \"as\", \"if\", \"when\", \"than\", \"because\", \"while\"],\n",
      "        \"question words\": [\"what\", \"who\", \"where\", \"when\", \"why\", \"how\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33muser\u001b[0m (to assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user):\n",
      "\n",
      "I'm sorry, but you didn't provide a language or a CEFR level. Please provide them so I can give the correct information.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33muser\u001b[0m (to assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user):\n",
      "\n",
      "You didn't provide any information. Could you please let me know which language and CEFR level you are interested in?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser\u001b[0m (to assistant):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "system_message = \"\"\"You are an AI Assistant. \n",
    "you are given a LANGUAGE and CEFR level, \n",
    "you provide a very broad and structured list of terminology that the user should know to achieve this CEFR LEVEL\n",
    "of the given LANGUAGE.\n",
    "You answer only in JSON.\n",
    "\"\"\"\n",
    "\n",
    "# 1. create an AssistantAgent instance named \"assistant\"\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\", \n",
    "    system_message=system_message,\n",
    "    llm_config={\n",
    "        \"timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    "    is_termination_msg=termination_msg\n",
    ")\n",
    "\n",
    "# Create the agent that represents the user in the conversation.\n",
    "user_proxy = autogen.UserProxyAgent(\"user\", code_execution_config=False, human_input_mode=\"NEVER\", max_consecutive_auto_reply=0,\n",
    ")\n",
    "\n",
    "user_message = \"\"\"English A1\"\"\"\n",
    "# the assistant receives a message from the user_proxy, which contains the task description\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=user_message,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
